{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.stem import PorterStemmer \n",
    "\n",
    "# vizualization\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "Check relations b/w:\n",
    "* keyword vs target\n",
    "* location vs target\n",
    "* target 1 & 0 ratio. (this ratio can be compared for training and test datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of real disaster tweets: 42.97%\n",
      "3342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x7200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data_og = pd.read_csv('./train.csv')\n",
    "test_data_og = pd.read_csv('./test.csv')\n",
    "\n",
    "# print(train_data_og.dtypes)\n",
    "# display(train_data_og.sample(n= 5).style)\n",
    "# print(train_data_og.isnull().sum(), test_data_og.isnull().sum())\n",
    "\n",
    "train_data = train_data_og.copy()\n",
    "print(f\"% of real disaster tweets: {np.round(np.sum(train_data['target'])/len(train_data)*100,2)}%\")\n",
    "train_data['target_sum'] = train_data.groupby('keyword')['target'].transform('sum')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 72), dpi=100)\n",
    "# sns.countplot(data = train_data, y = train_data.sort_values(by='target_sum', ascending= False)['keyword'],  hue='target')\n",
    "train_data.drop(columns=['target_sum'], inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "* (DONE) perform word tokenization\n",
    "* (DONE) Remove stop words\n",
    "* (DONE) Remove https links\n",
    "* (DONE) Remove punctuations\n",
    "* (DONE) lowercase strings\n",
    "* (DONE) apply stemming : reducing words to their root words\n",
    "* apply lemmatization? Study more about this\n",
    "* vectorization: Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_33ce0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_33ce0_level0_col0\" class=\"col_heading level0 col0\" >id</th>\n",
       "      <th id=\"T_33ce0_level0_col1\" class=\"col_heading level0 col1\" >keyword</th>\n",
       "      <th id=\"T_33ce0_level0_col2\" class=\"col_heading level0 col2\" >location</th>\n",
       "      <th id=\"T_33ce0_level0_col3\" class=\"col_heading level0 col3\" >text</th>\n",
       "      <th id=\"T_33ce0_level0_col4\" class=\"col_heading level0 col4\" >target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_33ce0_level0_row0\" class=\"row_heading level0 row0\" >4827</th>\n",
       "      <td id=\"T_33ce0_row0_col0\" class=\"data row0 col0\" >6874</td>\n",
       "      <td id=\"T_33ce0_row0_col1\" class=\"data row0 col1\" >mass%20murder</td>\n",
       "      <td id=\"T_33ce0_row0_col2\" class=\"data row0 col2\" >Anonymous</td>\n",
       "      <td id=\"T_33ce0_row0_col3\" class=\"data row0 col3\" >['royalcarribean', 'passeng', 'know', 'mass', 'murder', 'take', 'place', 'faroeisland', 'everi', 'year']</td>\n",
       "      <td id=\"T_33ce0_row0_col4\" class=\"data row0 col4\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_33ce0_level0_row1\" class=\"row_heading level0 row1\" >6626</th>\n",
       "      <td id=\"T_33ce0_row1_col0\" class=\"data row1 col0\" >9490</td>\n",
       "      <td id=\"T_33ce0_row1_col1\" class=\"data row1 col1\" >terrorism</td>\n",
       "      <td id=\"T_33ce0_row1_col2\" class=\"data row1 col2\" >nan</td>\n",
       "      <td id=\"T_33ce0_row1_col3\" class=\"data row1 col3\" >['truthnewsbbccnnislamtruthgodisisterrorismquranli']</td>\n",
       "      <td id=\"T_33ce0_row1_col4\" class=\"data row1 col4\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_33ce0_level0_row2\" class=\"row_heading level0 row2\" >7109</th>\n",
       "      <td id=\"T_33ce0_row2_col0\" class=\"data row2 col0\" >10186</td>\n",
       "      <td id=\"T_33ce0_row2_col1\" class=\"data row2 col1\" >violent%20storm</td>\n",
       "      <td id=\"T_33ce0_row2_col2\" class=\"data row2 col2\" >South Africa</td>\n",
       "      <td id=\"T_33ce0_row2_col3\" class=\"data row2 col3\" >['pov', 'footag', 'captur', 'violent', 'land', 'insid', 'plane', 'storm']</td>\n",
       "      <td id=\"T_33ce0_row2_col4\" class=\"data row2 col4\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_33ce0_level0_row3\" class=\"row_heading level0 row3\" >1359</th>\n",
       "      <td id=\"T_33ce0_row3_col0\" class=\"data row3 col0\" >1961</td>\n",
       "      <td id=\"T_33ce0_row3_col1\" class=\"data row3 col1\" >burning%20buildings</td>\n",
       "      <td id=\"T_33ce0_row3_col2\" class=\"data row3 col2\" >Copenhagen, Capital Region of Denmark</td>\n",
       "      <td id=\"T_33ce0_row3_col3\" class=\"data row3 col3\" >['dog', 'render', 'kitten', 'burn', 'build']</td>\n",
       "      <td id=\"T_33ce0_row3_col4\" class=\"data row3 col4\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_33ce0_level0_row4\" class=\"row_heading level0 row4\" >369</th>\n",
       "      <td id=\"T_33ce0_row4_col0\" class=\"data row4 col0\" >528</td>\n",
       "      <td id=\"T_33ce0_row4_col1\" class=\"data row4 col1\" >army</td>\n",
       "      <td id=\"T_33ce0_row4_col2\" class=\"data row4 col2\" >New York</td>\n",
       "      <td id=\"T_33ce0_row4_col3\" class=\"data row4 col3\" >['wwi', 'wwii', 'japanes', 'armi', 'navi', 'militari', 'japan', 'leather', 'watch', 'war', 'mido', 'full', 'read', 'ebay']</td>\n",
       "      <td id=\"T_33ce0_row4_col4\" class=\"data row4 col4\" >0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x190bf118df0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data= train_data.replace(to_replace= {'text':{r'http\\S+':'',r'[0-9]+':'',r'[^A-Za-z0-9 ]+':''}}, regex=True)\n",
    "\n",
    "train_data['text'] = train_data['text'].str.lower().apply(word_tokenize)\n",
    "\n",
    "stopwords_en = set(stopwords.words('english'))\n",
    "punctuation_en = set(punctuation)\n",
    "stopwords_punctuations_en = stopwords_en.union(punctuation_en)\n",
    "\n",
    "train_data['text'] = train_data['text'].apply(lambda x: [word for word in x if word not in stopwords_punctuations_en and len(word)>2 ])\n",
    "\n",
    "porter = PorterStemmer()\n",
    "train_data['text'] = train_data['text'].apply(lambda x : [porter.stem(word) for word in x ] )\n",
    "\n",
    "display(train_data.sample(n=5).style)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "* (DONE) Some tokens contain: \"'s\", \"--\", decimal numbers etc."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "* Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Coding prac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f58c01d3280ef83fc61600421c7c5ac6e7ea2fe2e0e9fc76fa916fea3bc77b6d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
