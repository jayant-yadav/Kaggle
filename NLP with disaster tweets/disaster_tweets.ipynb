{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.stem import PorterStemmer "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "Check relations b/w:\n",
    "* keyword vs target\n",
    "* location vs target\n",
    "* target 1 & 0 ratio. (this ratio can be compared for training and test datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id           int64\n",
      "keyword     object\n",
      "location    object\n",
      "text        object\n",
      "target       int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_1aaf1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_1aaf1_level0_col0\" class=\"col_heading level0 col0\" >id</th>\n",
       "      <th id=\"T_1aaf1_level0_col1\" class=\"col_heading level0 col1\" >keyword</th>\n",
       "      <th id=\"T_1aaf1_level0_col2\" class=\"col_heading level0 col2\" >location</th>\n",
       "      <th id=\"T_1aaf1_level0_col3\" class=\"col_heading level0 col3\" >text</th>\n",
       "      <th id=\"T_1aaf1_level0_col4\" class=\"col_heading level0 col4\" >target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1aaf1_level0_row0\" class=\"row_heading level0 row0\" >6424</th>\n",
       "      <td id=\"T_1aaf1_row0_col0\" class=\"data row0 col0\" >9185</td>\n",
       "      <td id=\"T_1aaf1_row0_col1\" class=\"data row0 col1\" >suicide%20bomber</td>\n",
       "      <td id=\"T_1aaf1_row0_col2\" class=\"data row0 col2\" >nigeria</td>\n",
       "      <td id=\"T_1aaf1_row0_col3\" class=\"data row0 col3\" >Suicide Bomber Kills More Than a Dozen in Saudi Mosque: Saudi Arabia have started experiencing some terrorist ... http://t.co/GuAJ2t910b</td>\n",
       "      <td id=\"T_1aaf1_row0_col4\" class=\"data row0 col4\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1aaf1_level0_row1\" class=\"row_heading level0 row1\" >489</th>\n",
       "      <td id=\"T_1aaf1_row1_col0\" class=\"data row1 col0\" >709</td>\n",
       "      <td id=\"T_1aaf1_row1_col1\" class=\"data row1 col1\" >attacked</td>\n",
       "      <td id=\"T_1aaf1_row1_col2\" class=\"data row1 col2\" >MAURITIUS</td>\n",
       "      <td id=\"T_1aaf1_row1_col3\" class=\"data row1 col3\" >Israeli helicopters that attacked civilians in Gaza just completed exercises in Greece.</td>\n",
       "      <td id=\"T_1aaf1_row1_col4\" class=\"data row1 col4\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1aaf1_level0_row2\" class=\"row_heading level0 row2\" >2991</th>\n",
       "      <td id=\"T_1aaf1_row2_col0\" class=\"data row2 col0\" >4298</td>\n",
       "      <td id=\"T_1aaf1_row2_col1\" class=\"data row2 col1\" >dust%20storm</td>\n",
       "      <td id=\"T_1aaf1_row2_col2\" class=\"data row2 col2\" >Idaho</td>\n",
       "      <td id=\"T_1aaf1_row2_col3\" class=\"data row2 col3\" >@NWSPocatello BG-16: So far brunt of storm just to our north. Grayed out w/ dust &amp; rain to N blue sky interspersed w/ clouds to S.</td>\n",
       "      <td id=\"T_1aaf1_row2_col4\" class=\"data row2 col4\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1aaf1_level0_row3\" class=\"row_heading level0 row3\" >6877</th>\n",
       "      <td id=\"T_1aaf1_row3_col0\" class=\"data row3 col0\" >9860</td>\n",
       "      <td id=\"T_1aaf1_row3_col1\" class=\"data row3 col1\" >traumatised</td>\n",
       "      <td id=\"T_1aaf1_row3_col2\" class=\"data row3 col2\" >Kirkwall</td>\n",
       "      <td id=\"T_1aaf1_row3_col3\" class=\"data row3 col3\" >WHY THE DEEP ROADS THO HAHAHAHA IM SO TRAUMATISED BY THE DEEP ROADS LOLOL</td>\n",
       "      <td id=\"T_1aaf1_row3_col4\" class=\"data row3 col4\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1aaf1_level0_row4\" class=\"row_heading level0 row4\" >7488</th>\n",
       "      <td id=\"T_1aaf1_row4_col0\" class=\"data row4 col0\" >10710</td>\n",
       "      <td id=\"T_1aaf1_row4_col1\" class=\"data row4 col1\" >wreck</td>\n",
       "      <td id=\"T_1aaf1_row4_col2\" class=\"data row4 col2\" >new york</td>\n",
       "      <td id=\"T_1aaf1_row4_col3\" class=\"data row4 col3\" >act my age was a MESS everyone was so wild it was so fun my videos a wreck</td>\n",
       "      <td id=\"T_1aaf1_row4_col4\" class=\"data row4 col4\" >0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x190bc50eeb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id             0\n",
      "keyword       61\n",
      "location    2533\n",
      "text           0\n",
      "target         0\n",
      "dtype: int64 id             0\n",
      "keyword       26\n",
      "location    1105\n",
      "text           0\n",
      "dtype: int64\n",
      "keyword vs target: \n",
      "keyword\n",
      "derailment     39\n",
      "wreckage       39\n",
      "outbreak       39\n",
      "typhoon        37\n",
      "debris         37\n",
      "               ..\n",
      "electrocute     1\n",
      "epicentre       1\n",
      "body%20bags     1\n",
      "blazing         1\n",
      "aftershock      0\n",
      "Name: target, Length: 221, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_data_og = pd.read_csv('./train.csv')\n",
    "test_data_og = pd.read_csv('./test.csv')\n",
    "\n",
    "print(train_data_og.dtypes)\n",
    "display(train_data_og.sample(n= 5).style)\n",
    "print(train_data_og.isnull().sum(), test_data_og.isnull().sum())\n",
    "\n",
    "print(f\"keyword vs target: \\n{train_data_og[['keyword','target']].groupby(['keyword'])['target'].sum().sort_values(ascending=False)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "* (DONE) perform word tokenization\n",
    "* (DONE) Remove stop words\n",
    "* (DONE) Remove https links\n",
    "* (DONE) Remove punctuations\n",
    "* (DONE) lowercase strings\n",
    "* (DONE) apply stemming : reducing words to their root words\n",
    "* apply lemmatization? Study more about this\n",
    "* vectorization: Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_2f0e0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2f0e0_level0_col0\" class=\"col_heading level0 col0\" >id</th>\n",
       "      <th id=\"T_2f0e0_level0_col1\" class=\"col_heading level0 col1\" >keyword</th>\n",
       "      <th id=\"T_2f0e0_level0_col2\" class=\"col_heading level0 col2\" >location</th>\n",
       "      <th id=\"T_2f0e0_level0_col3\" class=\"col_heading level0 col3\" >text</th>\n",
       "      <th id=\"T_2f0e0_level0_col4\" class=\"col_heading level0 col4\" >target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2f0e0_level0_row0\" class=\"row_heading level0 row0\" >4060</th>\n",
       "      <td id=\"T_2f0e0_row0_col0\" class=\"data row0 col0\" >5769</td>\n",
       "      <td id=\"T_2f0e0_row0_col1\" class=\"data row0 col1\" >forest%20fires</td>\n",
       "      <td id=\"T_2f0e0_row0_col2\" class=\"data row0 col2\" >nan</td>\n",
       "      <td id=\"T_2f0e0_row0_col3\" class=\"data row0 col3\" >['heartdiseas', 'forest', 'servic', 'say', 'spend', 'half', 'budget', 'fire']</td>\n",
       "      <td id=\"T_2f0e0_row0_col4\" class=\"data row0 col4\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2f0e0_level0_row1\" class=\"row_heading level0 row1\" >3028</th>\n",
       "      <td id=\"T_2f0e0_row1_col0\" class=\"data row1 col0\" >4349</td>\n",
       "      <td id=\"T_2f0e0_row1_col1\" class=\"data row1 col1\" >earthquake</td>\n",
       "      <td id=\"T_2f0e0_row1_col2\" class=\"data row1 col2\" >Earth</td>\n",
       "      <td id=\"T_2f0e0_row1_col3\" class=\"data row1 col3\" >['earthquak', 'occur', 'near', 'mount', 'helen', 'area', 'washington', 'utc', 'earthquak']</td>\n",
       "      <td id=\"T_2f0e0_row1_col4\" class=\"data row1 col4\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2f0e0_level0_row2\" class=\"row_heading level0 row2\" >4478</th>\n",
       "      <td id=\"T_2f0e0_row2_col0\" class=\"data row2 col0\" >6370</td>\n",
       "      <td id=\"T_2f0e0_row2_col1\" class=\"data row2 col1\" >hostages</td>\n",
       "      <td id=\"T_2f0e0_row2_col2\" class=\"data row2 col2\" >nan</td>\n",
       "      <td id=\"T_2f0e0_row2_col3\" class=\"data row2 col3\" >['new', 'free', 'porn', 'clip', 'take', 'hostag', 'danger', 'favor', 'free', 'adult', 'sex', 'tube']</td>\n",
       "      <td id=\"T_2f0e0_row2_col4\" class=\"data row2 col4\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2f0e0_level0_row3\" class=\"row_heading level0 row3\" >5368</th>\n",
       "      <td id=\"T_2f0e0_row3_col0\" class=\"data row3 col0\" >7659</td>\n",
       "      <td id=\"T_2f0e0_row3_col1\" class=\"data row3 col1\" >panic</td>\n",
       "      <td id=\"T_2f0e0_row3_col2\" class=\"data row3 col2\" >Narnia</td>\n",
       "      <td id=\"T_2f0e0_row3_col3\" class=\"data row3 col3\" >['ad', 'video', 'youtub', 'playlist', 'panic', 'disco', 'girlsgirlsboy', 'offici', 'video']</td>\n",
       "      <td id=\"T_2f0e0_row3_col4\" class=\"data row3 col4\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2f0e0_level0_row4\" class=\"row_heading level0 row4\" >485</th>\n",
       "      <td id=\"T_2f0e0_row4_col0\" class=\"data row4 col0\" >702</td>\n",
       "      <td id=\"T_2f0e0_row4_col1\" class=\"data row4 col1\" >attacked</td>\n",
       "      <td id=\"T_2f0e0_row4_col2\" class=\"data row4 col2\" >Texas, USA</td>\n",
       "      <td id=\"T_2f0e0_row4_col3\" class=\"data row4 col3\" >['messeymetoo', 'feel', 'attack']</td>\n",
       "      <td id=\"T_2f0e0_row4_col4\" class=\"data row4 col4\" >0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x190bdfe4eb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = train_data_og.copy()\n",
    "\n",
    "train_data= train_data.replace(to_replace= {'text':{r'http\\S+':'',r'[0-9]+':'',r'[^A-Za-z0-9 ]+':''}}, regex=True)\n",
    "\n",
    "train_data['text'] = train_data['text'].str.lower().apply(word_tokenize)\n",
    "\n",
    "stopwords_en = set(stopwords.words('english'))\n",
    "punctuation_en = set(punctuation)\n",
    "stopwords_punctuations_en = stopwords_en.union(punctuation_en)\n",
    "\n",
    "train_data['text'] = train_data['text'].apply(lambda x: [word for word in x if word not in stopwords_punctuations_en and len(word)>2 ])\n",
    "\n",
    "porter = PorterStemmer()\n",
    "train_data['text'] = train_data['text'].apply(lambda x : [porter.stem(word) for word in x ] )\n",
    "\n",
    "display(train_data.sample(n=5).style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_f5716\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f5716_level0_col0\" class=\"col_heading level0 col0\" >text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f5716_level0_row0\" class=\"row_heading level0 row0\" >6324</th>\n",
       "      <td id=\"T_f5716_row0_col0\" class=\"data row0 col0\" >['stretcher', 'witter', 'rexyy', 'towel', 'show', 'pictur']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5716_level0_row1\" class=\"row_heading level0 row1\" >3830</th>\n",
       "      <td id=\"T_f5716_row1_col0\" class=\"data row1 col0\" >['good', 'info', 'help', 'first', 'respond', 'cope', 'individu', 'resili', 'factsheet', 'respond']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5716_level0_row2\" class=\"row_heading level0 row2\" >1665</th>\n",
       "      <td id=\"T_f5716_row2_col0\" class=\"data row2 col0\" >['like', 'youtub', 'video', 'sqwizzix', 'call', 'duti', 'piano', 'entertain', 'musician', 'collid']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5716_level0_row3\" class=\"row_heading level0 row3\" >2330</th>\n",
       "      <td id=\"T_f5716_row3_col0\" class=\"data row3 col0\" >['three', 'home', 'demolish', 'unrecogn', 'arab', 'villag', 'intern', 'middl', 'east', 'media', 'center']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5716_level0_row4\" class=\"row_heading level0 row4\" >1470</th>\n",
       "      <td id=\"T_f5716_row4_col0\" class=\"data row4 col0\" >['peterjuk', 'good', 'ground', 'believ', 'polit', 'militari', 'catastroph', 'crime', 'plan', 'commit', 'individu']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5716_level0_row5\" class=\"row_heading level0 row5\" >53</th>\n",
       "      <td id=\"T_f5716_row5_col0\" class=\"data row5 col0\" >['polic', 'arsonist', 'deliber', 'set', 'black', 'church', 'north', 'carolinaablaz']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5716_level0_row6\" class=\"row_heading level0 row6\" >936</th>\n",
       "      <td id=\"T_f5716_row6_col0\" class=\"data row6 col0\" >['blown', 'away', 'extens', 'noth', 'weve', 'seen', 'mani', 'option', 'one']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5716_level0_row7\" class=\"row_heading level0 row7\" >4803</th>\n",
       "      <td id=\"T_f5716_row7_col0\" class=\"data row7 col0\" >['toxicsavior', 'loud', 'bang', 'froze', 'spot', 'slowli', 'everi', 'head', 'turn', 'toward', 'one', 'thing', 'hate']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5716_level0_row8\" class=\"row_heading level0 row8\" >5851</th>\n",
       "      <td id=\"T_f5716_row8_col0\" class=\"data row8 col0\" >['well', 'done', 'everyon', 'applaud', 'terrif', 'never', 'ruin', 'anyth']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5716_level0_row9\" class=\"row_heading level0 row9\" >6822</th>\n",
       "      <td id=\"T_f5716_row9_col0\" class=\"data row9 col0\" >['hollywood', 'movi', 'trap', 'miner', 'releas', 'chile', 'zippednew']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x190ba9ee130>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nprfreshair', 'realli', 'cant', 'believ', 'skip', 'republican', 'meltdowni', 'mean', 'debat']\n"
     ]
    }
   ],
   "source": [
    "display(train_data[['text']].sample(n=10).style)\n",
    "print(train_data.loc[4961,'text'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "* Some tokens contain: \"'s\", \"--\", decimal numbers etc."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "* Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Coding prac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f58c01d3280ef83fc61600421c7c5ac6e7ea2fe2e0e9fc76fa916fea3bc77b6d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
