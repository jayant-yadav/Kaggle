{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.stem import PorterStemmer "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "Check relations b/w:\n",
    "* keyword vs target\n",
    "* location vs target\n",
    "* target 1 & 0 ratio. (this ratio can be compared for training and test datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id           int64\n",
      "keyword     object\n",
      "location    object\n",
      "text        object\n",
      "target       int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_1aaf1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_1aaf1_level0_col0\" class=\"col_heading level0 col0\" >id</th>\n",
       "      <th id=\"T_1aaf1_level0_col1\" class=\"col_heading level0 col1\" >keyword</th>\n",
       "      <th id=\"T_1aaf1_level0_col2\" class=\"col_heading level0 col2\" >location</th>\n",
       "      <th id=\"T_1aaf1_level0_col3\" class=\"col_heading level0 col3\" >text</th>\n",
       "      <th id=\"T_1aaf1_level0_col4\" class=\"col_heading level0 col4\" >target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1aaf1_level0_row0\" class=\"row_heading level0 row0\" >6424</th>\n",
       "      <td id=\"T_1aaf1_row0_col0\" class=\"data row0 col0\" >9185</td>\n",
       "      <td id=\"T_1aaf1_row0_col1\" class=\"data row0 col1\" >suicide%20bomber</td>\n",
       "      <td id=\"T_1aaf1_row0_col2\" class=\"data row0 col2\" >nigeria</td>\n",
       "      <td id=\"T_1aaf1_row0_col3\" class=\"data row0 col3\" >Suicide Bomber Kills More Than a Dozen in Saudi Mosque: Saudi Arabia have started experiencing some terrorist ... http://t.co/GuAJ2t910b</td>\n",
       "      <td id=\"T_1aaf1_row0_col4\" class=\"data row0 col4\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1aaf1_level0_row1\" class=\"row_heading level0 row1\" >489</th>\n",
       "      <td id=\"T_1aaf1_row1_col0\" class=\"data row1 col0\" >709</td>\n",
       "      <td id=\"T_1aaf1_row1_col1\" class=\"data row1 col1\" >attacked</td>\n",
       "      <td id=\"T_1aaf1_row1_col2\" class=\"data row1 col2\" >MAURITIUS</td>\n",
       "      <td id=\"T_1aaf1_row1_col3\" class=\"data row1 col3\" >Israeli helicopters that attacked civilians in Gaza just completed exercises in Greece.</td>\n",
       "      <td id=\"T_1aaf1_row1_col4\" class=\"data row1 col4\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1aaf1_level0_row2\" class=\"row_heading level0 row2\" >2991</th>\n",
       "      <td id=\"T_1aaf1_row2_col0\" class=\"data row2 col0\" >4298</td>\n",
       "      <td id=\"T_1aaf1_row2_col1\" class=\"data row2 col1\" >dust%20storm</td>\n",
       "      <td id=\"T_1aaf1_row2_col2\" class=\"data row2 col2\" >Idaho</td>\n",
       "      <td id=\"T_1aaf1_row2_col3\" class=\"data row2 col3\" >@NWSPocatello BG-16: So far brunt of storm just to our north. Grayed out w/ dust &amp; rain to N blue sky interspersed w/ clouds to S.</td>\n",
       "      <td id=\"T_1aaf1_row2_col4\" class=\"data row2 col4\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1aaf1_level0_row3\" class=\"row_heading level0 row3\" >6877</th>\n",
       "      <td id=\"T_1aaf1_row3_col0\" class=\"data row3 col0\" >9860</td>\n",
       "      <td id=\"T_1aaf1_row3_col1\" class=\"data row3 col1\" >traumatised</td>\n",
       "      <td id=\"T_1aaf1_row3_col2\" class=\"data row3 col2\" >Kirkwall</td>\n",
       "      <td id=\"T_1aaf1_row3_col3\" class=\"data row3 col3\" >WHY THE DEEP ROADS THO HAHAHAHA IM SO TRAUMATISED BY THE DEEP ROADS LOLOL</td>\n",
       "      <td id=\"T_1aaf1_row3_col4\" class=\"data row3 col4\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1aaf1_level0_row4\" class=\"row_heading level0 row4\" >7488</th>\n",
       "      <td id=\"T_1aaf1_row4_col0\" class=\"data row4 col0\" >10710</td>\n",
       "      <td id=\"T_1aaf1_row4_col1\" class=\"data row4 col1\" >wreck</td>\n",
       "      <td id=\"T_1aaf1_row4_col2\" class=\"data row4 col2\" >new york</td>\n",
       "      <td id=\"T_1aaf1_row4_col3\" class=\"data row4 col3\" >act my age was a MESS everyone was so wild it was so fun my videos a wreck</td>\n",
       "      <td id=\"T_1aaf1_row4_col4\" class=\"data row4 col4\" >0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x190bc50eeb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id             0\n",
      "keyword       61\n",
      "location    2533\n",
      "text           0\n",
      "target         0\n",
      "dtype: int64 id             0\n",
      "keyword       26\n",
      "location    1105\n",
      "text           0\n",
      "dtype: int64\n",
      "keyword vs target: \n",
      "keyword\n",
      "derailment     39\n",
      "wreckage       39\n",
      "outbreak       39\n",
      "typhoon        37\n",
      "debris         37\n",
      "               ..\n",
      "electrocute     1\n",
      "epicentre       1\n",
      "body%20bags     1\n",
      "blazing         1\n",
      "aftershock      0\n",
      "Name: target, Length: 221, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_data_og = pd.read_csv('./train.csv')\n",
    "test_data_og = pd.read_csv('./test.csv')\n",
    "\n",
    "print(train_data_og.dtypes)\n",
    "display(train_data_og.sample(n= 5).style)\n",
    "print(train_data_og.isnull().sum(), test_data_og.isnull().sum())\n",
    "\n",
    "print(f\"keyword vs target: \\n{train_data_og[['keyword','target']].groupby(['keyword'])['target'].sum().sort_values(ascending=False)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "* (DONE) perform word tokenization\n",
    "* (DONE) Remove stop words\n",
    "* Remove https links\n",
    "* (DONE) Remove punctuations\n",
    "* (DONE) lowercase strings\n",
    "* (DONE) apply stemming : reducing words to their root words\n",
    "* apply lemmatization?\n",
    "* vectorization: Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_ed461\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ed461_level0_col0\" class=\"col_heading level0 col0\" >id</th>\n",
       "      <th id=\"T_ed461_level0_col1\" class=\"col_heading level0 col1\" >keyword</th>\n",
       "      <th id=\"T_ed461_level0_col2\" class=\"col_heading level0 col2\" >location</th>\n",
       "      <th id=\"T_ed461_level0_col3\" class=\"col_heading level0 col3\" >text</th>\n",
       "      <th id=\"T_ed461_level0_col4\" class=\"col_heading level0 col4\" >target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ed461_level0_row0\" class=\"row_heading level0 row0\" >5828</th>\n",
       "      <td id=\"T_ed461_row0_col0\" class=\"data row0 col0\" >8321</td>\n",
       "      <td id=\"T_ed461_row0_col1\" class=\"data row0 col1\" >rubble</td>\n",
       "      <td id=\"T_ed461_row0_col2\" class=\"data row0 col2\" >Spain - China - Latin America.</td>\n",
       "      <td id=\"T_ed461_row0_col3\" class=\"data row0 col3\" >['china', \"'s\", 'stock', 'market', 'crash', 'gem', 'rubbl', 'china\\x89ûª', 'stock', 'market', 'crash', 'summer', 'h', '...', 'http', '//t.co/pe2r3ln16o', '.forb']</td>\n",
       "      <td id=\"T_ed461_row0_col4\" class=\"data row0 col4\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed461_level0_row1\" class=\"row_heading level0 row1\" >1200</th>\n",
       "      <td id=\"T_ed461_row1_col0\" class=\"data row1 col0\" >1726</td>\n",
       "      <td id=\"T_ed461_row1_col1\" class=\"data row1 col1\" >buildings%20burning</td>\n",
       "      <td id=\"T_ed461_row1_col2\" class=\"data row1 col2\" >nan</td>\n",
       "      <td id=\"T_ed461_row1_col3\" class=\"data row1 col3\" >['kou', 'like', 'cash', 'regist', 'build', 'burn']</td>\n",
       "      <td id=\"T_ed461_row1_col4\" class=\"data row1 col4\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed461_level0_row2\" class=\"row_heading level0 row2\" >6840</th>\n",
       "      <td id=\"T_ed461_row2_col0\" class=\"data row2 col0\" >9797</td>\n",
       "      <td id=\"T_ed461_row2_col1\" class=\"data row2 col1\" >trapped</td>\n",
       "      <td id=\"T_ed461_row2_col2\" class=\"data row2 col2\" >nan</td>\n",
       "      <td id=\"T_ed461_row2_col3\" class=\"data row2 col3\" >['hollywood', 'movi', 'trap', 'miner', 'releas', 'chile', \"'the\", 'hollywood', 'movi', 'trap', 'miner', 'star', '...', 'http', '//t.co/0f8xa4ih1u']</td>\n",
       "      <td id=\"T_ed461_row2_col4\" class=\"data row2 col4\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed461_level0_row3\" class=\"row_heading level0 row3\" >1837</th>\n",
       "      <td id=\"T_ed461_row3_col0\" class=\"data row3 col0\" >2642</td>\n",
       "      <td id=\"T_ed461_row3_col1\" class=\"data row3 col1\" >crashed</td>\n",
       "      <td id=\"T_ed461_row3_col2\" class=\"data row3 col2\" >too far</td>\n",
       "      <td id=\"T_ed461_row3_col3\" class=\"data row3 col3\" >['.4', 'second', 'faster', 'overtook', 'twice', 'crash', 'tru', 'luv', 'lt', 'lt']</td>\n",
       "      <td id=\"T_ed461_row3_col4\" class=\"data row3 col4\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ed461_level0_row4\" class=\"row_heading level0 row4\" >1014</th>\n",
       "      <td id=\"T_ed461_row4_col0\" class=\"data row4 col0\" >1473</td>\n",
       "      <td id=\"T_ed461_row4_col1\" class=\"data row4 col1\" >body%20bagging</td>\n",
       "      <td id=\"T_ed461_row4_col2\" class=\"data row4 col2\" >nan</td>\n",
       "      <td id=\"T_ed461_row4_col3\" class=\"data row4 col3\" >['\\x89ûï', 'macdaddy_leo', 'caption', 'need', 'freshman', '...', 'http', '//t.co/k8ughv2aif\\x89û\\x9dmi', 'nigga', 'stacey', 'bodi', 'bag', 'nigga']</td>\n",
       "      <td id=\"T_ed461_row4_col4\" class=\"data row4 col4\" >1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x190bd3bd0a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = train_data_og.copy()\n",
    "train_data['text'] = train_data['text'].str.lower().apply(word_tokenize)\n",
    "\n",
    "stopwords_en = set(stopwords.words('english'))\n",
    "punctuation_en = set(punctuation)\n",
    "stopwords_punctuations_en = stopwords_en.union(punctuation_en)\n",
    "\n",
    "train_data['text'] = train_data['text'].apply(lambda x: [word for word in x if word not in stopwords_punctuations_en and not word.isdigit()])\n",
    "\n",
    "porter = PorterStemmer()\n",
    "train_data['text'] = train_data['text'].apply(lambda x : [porter.stem(word) for word in x ] )\n",
    "\n",
    "display(train_data.sample(n=5).style)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "* Some tokens contain: \"'s\", \"--\", decimal numbers etc."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "* Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Coding prac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f58c01d3280ef83fc61600421c7c5ac6e7ea2fe2e0e9fc76fa916fea3bc77b6d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
